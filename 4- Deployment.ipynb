{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increasing-addiction",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re \n",
    "import pyarabic.araby as ar\n",
    "import unicodedata as ud\n",
    "\n",
    "# Creat dictionary with country name and short name\n",
    "country_name = {'IQ': 'Iraq', 'SY':'Syria', 'LY':'Libya', 'EG':'Egypt', 'YE':'Yemen', 'OM':'Oman', 'BH':'Bahrain',\n",
    "               'KW':'Kuwait', 'SA':'Saudi Arabia', 'AE':'United Arab Emirates', 'QA':'Qatar', 'DZ':'Algeria', 'MA':'Morocco',\n",
    "                'TN':'Tunisia', 'SD':'Sudan ', 'JO':'Jordan', 'LB':'Lebanon', 'PL':'Palestine'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-delivery",
   "metadata": {},
   "source": [
    "## Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  \n",
    "        u\"\\u3030\"\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    text = regrex_pattern.sub(r' ',text)\n",
    "    text = re.sub(\"\\d+\", \" \", text)\n",
    "    text = re.sub(\"[a-zA-Z]\", \" \", text)\n",
    "    text = re.sub('\\u0621', '\\u0627', text)\n",
    "    text = re.sub('\\u0649', '\\u064a', text)\n",
    "    text = re.sub('\\u0629', '\\u0647', text)\n",
    "    text = re.sub('\\u06af', '\\u0643', text)\n",
    "    text = re.sub('\\u0686', '\\u062c', text)\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = ar.strip_tashkeel(text)\n",
    "    text = ar.strip_tatweel(text)\n",
    "    text = ar.normalize_hamza(text)\n",
    "    text = ar.strip_diacritics(text)\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)  # keep 2 repeat\n",
    "    text =  ''.join([c if not ud.category(c).startswith('P') else ' ' for c in text])\n",
    "    text = re.sub(r' +', ' ' , text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-intention",
   "metadata": {},
   "source": [
    "## Deploy with Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "flask_app = Flask(__name__)\n",
    "\n",
    "# Load machine learning trained files\n",
    "victorizer = pickle.load(open('./Machine_learning_pickles/victorizer.sav', 'rb'))\n",
    "transformer = pickle.load(open('./Machine_learning_pickles/transformer.sav', 'rb'))\n",
    "machine_model = pickle.load(open('./Machine_learning_pickles/linearSVC.sav', 'rb'))\n",
    "\n",
    "# Load deep learning trained files\n",
    "deep_model = load_model('./Deep_model_pickles/deep_model.h5')\n",
    "encoder = pickle.load(open('./Deep_model_pickles/encoder.sav', 'rb'))\n",
    "tokenizer = pickle.load(open('./Deep_model_pickles/tokenizer.sav', 'rb'))\n",
    "\n",
    "# Method to predict the result with machine leanring model\n",
    "def get_machine_result(input_text):\n",
    "    input_text = cleaner(input_text)\n",
    "    if len(input_text) < 3:\n",
    "        return 'Tweet is too short or its not arabic, Please enter valid text'\n",
    "    t = victorizer.transform([input_text])\n",
    "    t = transformer.transform(t)\n",
    "    result = machine_model.predict(t)\n",
    "    return country_name[result[0]]\n",
    "\n",
    "# Method to predict the result with deep leanring model\n",
    "def get_deep_result(input_text):\n",
    "    input_text = cleaner(input_text)\n",
    "    if len(input_text) < 3:\n",
    "        return 'Tweet is too short or its not arabic, Please enter valid text'\n",
    "    txt = pad_sequences(tokenizer.texts_to_sequences([input_text]), maxlen=300)\n",
    "    t = encoder.classes_[np.argmax(deep_model.predict(txt))]\n",
    "    return country_name[t]\n",
    "\n",
    "# Get Html template\n",
    "@flask_app.route(\"/\")\n",
    "def Home():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@flask_app.route(\"/predict\", methods = [\"POST\"])\n",
    "def predict():\n",
    "    vals = [str(x) for x in request.form.values()]\n",
    "    machine_result = get_machine_result(vals[0])\n",
    "    deep_result = get_deep_result(vals[0])\n",
    "    return render_template(\"index.html\", machine_learning = f\"Machine Learning prediction: {machine_result}\", \n",
    "                           deep_learning = f\"Deep Learning prediction: {deep_result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    flask_app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "based-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'building dialect classifiers using twitter data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'BUILDING DIALECT CLASSIFIERS USING TWITTER DATA'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-projector",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
